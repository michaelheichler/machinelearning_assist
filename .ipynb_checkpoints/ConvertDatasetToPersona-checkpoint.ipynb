{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from typing import Dict, Any, Callable, List, Tuple, Optional, Union\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, DistilBertModel, DistilBertTokenizer\n",
    "from transformers import (AdamW, OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_class = OpenAIGPTTokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert DF to CONVERSATION Dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_conv_ai_dict(df: pd.DataFrame,\n",
    "                               personality: List[str],\n",
    "                               response_columns: List[str],\n",
    "                               tokenizer: Callable[[str], List[str]],\n",
    "                               max_tokens: Optional[int] = None,\n",
    "                               n_candidates: int = 6\n",
    "                               ) -> Dict[str, List[Any]]:  \n",
    "    # Add one because the index of the dataframe is the 0th position.\n",
    "    tuple_map = {name: index + 1 for index, name in enumerate(df.columns.tolist())}\n",
    "    train = []\n",
    "    val = []\n",
    "    # Step through every row in the dictionary\n",
    "    for row in df.itertuples():\n",
    "        question_text = row[tuple_map[\"body_1\"]]\n",
    "        for response_column in response_columns:\n",
    "            candidates = sample_candidates(df, row[tuple_map[\"id\"]], \"id\", \"body\", n_candidates)\n",
    "            # questions = sample_candidates(df, row[tuple_map[\"id\"]], \"id\", \"body_1\", n_candidates)\n",
    "            if max_tokens is not None: \n",
    "                questions = tokenizer.convert_tokens_to_string(tokenizer.tokenize(question_text)[:max_tokens])\n",
    "                candidates = [tokenizer.convert_tokens_to_string(tokenizer.tokenize(candidate)[:max_tokens]) for candidate in candidates]\n",
    "                d = {\"personality\": personality,\n",
    "                     \"utterances\": [{\"history\": questions,\n",
    "                                     \"candidates\": candidates}]}\n",
    "                if getattr(row, \"split\") == \"train\":\n",
    "                    train.append(d)\n",
    "                elif getattr(row, \"split\") == \"val\":\n",
    "                    val.append(d)\n",
    "                    \n",
    "    data = {\"train\": train, \"valid\": val}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Sampling, see coment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_candidates(df: pd.DataFrame, current_id: Any, id_column: int, text_column: str, n: int) -> List[str]:\n",
    "    \"\"\"Samples candidate responses to a question from the dataframe\n",
    "\n",
    "    It is aware of data splits and only samples from within the same split.  This avoids\n",
    "    leaking information between training validation and testing.  The sampled responses are\n",
    "    also drawn from all rows which do not have the same id as the current_id\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe we want to sample responses from\n",
    "        current_id: The unique identifier we would like to leave out of our sampling\n",
    "        id_column: The column name in the dataframe with the unique ids.  current_id should\n",
    "            be an element of this column\n",
    "        text_column: The column with the text we want to sample\n",
    "        n: How many samples we want to take.\n",
    "\n",
    "    Returns:\n",
    "        A list of samples strings from our dataframe.\n",
    "    \"\"\"\n",
    "    # We must only sample candidates from the correct data split to avoid information leakage across channels\n",
    "    split = df[df[id_column] == current_id][\"split\"].tolist()[0]\n",
    "    candidate_df = df[df[\"split\"] == split]\n",
    "\n",
    "    # Sample 3 random rows from the dataframe not matching the current id\n",
    "    sampled_texts = candidate_df[candidate_df[id_column] != current_id].sample(n + 15)[text_column].tolist()\n",
    "    \n",
    "\n",
    "    # join them all\n",
    "    text = \" \".join(sampled_texts)\n",
    "    \n",
    "    # Replace all newlines with spaces...\n",
    "    text_no_newline = re.sub(\"\\n\", \" \", text).lower()\n",
    "\n",
    "    # Split on punctuation\n",
    "    split_text = re.split('[?.!]', text_no_newline)\n",
    "\n",
    "    # Remove all empty lines\n",
    "    filtered_text = [x.strip() for x in split_text if len(x.strip()) > 1]\n",
    "\n",
    "    # Shuffle the list\n",
    "    return np.random.choice(filtered_text, n).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset from Bigquery which includes a siterip from Stackoverflow. The column body inherits all answers of the questions which are shown in the column body_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"answers.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=50000, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>body_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315636</th>\n",
       "      <td>315636</td>\n",
       "      <td>9478564</td>\n",
       "      <td>There used the vloopback driver, which did exa...</td>\n",
       "      <td>493362.0</td>\n",
       "      <td>I'm trying to develop a \"virtual\" video driver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91595</th>\n",
       "      <td>91595</td>\n",
       "      <td>26083642</td>\n",
       "      <td>Putty is an ssh client, not a shell. In bash, ...</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>In python command line, it gives 1 and I want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156882</th>\n",
       "      <td>156882</td>\n",
       "      <td>22042772</td>\n",
       "      <td>If you are talking about accessing the same re...</td>\n",
       "      <td>1839777.0</td>\n",
       "      <td>What is the best approach if I want to use the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195416</th>\n",
       "      <td>195416</td>\n",
       "      <td>37948761</td>\n",
       "      <td>I'm not really sure why but updating my AMI fi...</td>\n",
       "      <td>2678768.0</td>\n",
       "      <td>I'm having difficulty creating my cloud format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256334</th>\n",
       "      <td>256334</td>\n",
       "      <td>11242591</td>\n",
       "      <td>You are confusing the purpose of the printk pr...</td>\n",
       "      <td>457237.0</td>\n",
       "      <td>In the book LDD3 by Rubini, under the printk s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        id  \\\n",
       "315636      315636   9478564   \n",
       "91595        91595  26083642   \n",
       "156882      156882  22042772   \n",
       "195416      195416  37948761   \n",
       "256334      256334  11242591   \n",
       "\n",
       "                                                     body  owner_user_id  \\\n",
       "315636  There used the vloopback driver, which did exa...       493362.0   \n",
       "91595   Putty is an ssh client, not a shell. In bash, ...         9990.0   \n",
       "156882  If you are talking about accessing the same re...      1839777.0   \n",
       "195416  I'm not really sure why but updating my AMI fi...      2678768.0   \n",
       "256334  You are confusing the purpose of the printk pr...       457237.0   \n",
       "\n",
       "                                                   body_1  \n",
       "315636  I'm trying to develop a \"virtual\" video driver...  \n",
       "91595   In python command line, it gives 1 and I want ...  \n",
       "156882  What is the best approach if I want to use the...  \n",
       "195416  I'm having difficulty creating my cloud format...  \n",
       "256334  In the book LDD3 by Rubini, under the printk s...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['owner_user_id'], axis=1)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
    "\n",
    "for char in spec_chars:\n",
    "    df['body'] = df['body'].str.replace(char, ' ')\n",
    "\n",
    "for char in spec_chars:\n",
    "    df['body_1'] = df['body_1'].str.replace(char, ' ')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].str.split().str.join(\" \")\n",
    "df['body_1'] = df['body_1'].str.split().str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['body'].str.lower()\n",
    "df['body_1'] = df['body_1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>body_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315636</th>\n",
       "      <td>9478564</td>\n",
       "      <td>there used the vloopback driver which did exac...</td>\n",
       "      <td>i m trying to develop a virtual video driver b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91595</th>\n",
       "      <td>26083642</td>\n",
       "      <td>putty is an ssh client not a shell in bash whi...</td>\n",
       "      <td>in python command line it gives 1 and i want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156882</th>\n",
       "      <td>22042772</td>\n",
       "      <td>if you are talking about accessing the same re...</td>\n",
       "      <td>what is the best approach if i want to use the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195416</th>\n",
       "      <td>37948761</td>\n",
       "      <td>i m not really sure why but updating my ami fi...</td>\n",
       "      <td>i m having difficulty creating my cloud format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256334</th>\n",
       "      <td>11242591</td>\n",
       "      <td>you are confusing the purpose of the printk pr...</td>\n",
       "      <td>in the book ldd3 by rubini under the printk se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               body  \\\n",
       "315636   9478564  there used the vloopback driver which did exac...   \n",
       "91595   26083642  putty is an ssh client not a shell in bash whi...   \n",
       "156882  22042772  if you are talking about accessing the same re...   \n",
       "195416  37948761  i m not really sure why but updating my ami fi...   \n",
       "256334  11242591  you are confusing the purpose of the printk pr...   \n",
       "\n",
       "                                                   body_1  \n",
       "315636  i m trying to develop a virtual video driver b...  \n",
       "91595   in python command line it gives 1 and i want t...  \n",
       "156882  what is the best approach if i want to use the...  \n",
       "195416  i m having difficulty creating my cloud format...  \n",
       "256334  in the book ldd3 by rubini under the printk se...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"split\"] = \"\"\n",
    "df_1 = df.split.apply(lambda x: random.choice(['train', 'val']) ) \n",
    "df['split'] = df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = convert_df_to_conv_ai_dict(df, [\"\"], [\"body\"], tokenizer, max_tokens=250, n_candidates=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens_stack.json\", \"w\") as json_file:\n",
    "    json.dump(d, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
